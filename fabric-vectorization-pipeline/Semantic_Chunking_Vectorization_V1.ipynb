{"cells":[{"cell_type":"markdown","source":["\n","#### Semantic Chunking using Azure AI Document Intelligence and Vectorization using AI Search"],"metadata":{"jupyter":{"magics_cell_name":"magics-cell-markdown","magics_signature":"27ac753c3c60167f65c4d05fa7809cd85f1f0273d5b842aca4f65a01"},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e215debe-6b6e-4026-88bd-5422bcc592b0"},{"cell_type":"markdown","source":["**Setup**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"81a39208-2150-45ab-8cc6-fd255d56fa08"},{"cell_type":"code","source":["# Welcome to your new notebook\n","# Type here in the cell editor to add code!\n","\n","%pip install python-dotenv -q\n","%pip install langchain -q\n","%pip install langchain-community -q\n","%pip install langchain-openai  -q\n","%pip install langchainhub -q\n","%pip install openai --upgrade -q\n","%pip install tiktoken -q\n","%pip install azure-ai-documentintelligence -q\n","%pip install azure-identity -q\n","%pip install azure-search-documents==11.6.0b3 -q\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":17,"statement_ids":[3,4,5,6,7,8,9,10,11,12,13,14,15,16,17],"livy_statement_state":"available","session_id":"b74fc4a9-bb55-4427-ad4e-1ea1a17872aa","state":"finished","normalized_state":"finished","queued_time":"2024-07-30T01:25:10.8097834Z","session_start_time":"2024-07-30T01:25:11.0294557Z","execution_start_time":"2024-07-30T01:25:22.4748321Z","execution_finish_time":"2024-07-30T01:26:18.5871268Z","parent_msg_id":"2f3c5035-9200-4fee-8b6c-f04d9b56aa6e"},"text/plain":"StatementMeta(, b74fc4a9-bb55-4427-ad4e-1ea1a17872aa, 17, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[33mDEPRECATION: notebookutils 3.5.0-20240224.2 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of notebookutils or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n\u001b[33mDEPRECATION: notebookutils 3.5.0-20240224.2 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of notebookutils or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n\u001b[33mDEPRECATION: notebookutils 3.5.0-20240224.2 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of notebookutils or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n\u001b[33mDEPRECATION: notebookutils 3.5.0-20240224.2 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of notebookutils or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n\u001b[33mDEPRECATION: notebookutils 3.5.0-20240224.2 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of notebookutils or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n\u001b[33mDEPRECATION: notebookutils 3.5.0-20240224.2 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of notebookutils or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n\u001b[33mDEPRECATION: notebookutils 3.5.0-20240224.2 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of notebookutils or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n\u001b[33mDEPRECATION: notebookutils 3.5.0-20240224.2 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of notebookutils or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n\u001b[33mDEPRECATION: notebookutils 3.5.0-20240224.2 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of notebookutils or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n\u001b[33mDEPRECATION: notebookutils 3.5.0-20240224.2 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of notebookutils or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ebc2bc9e-3e27-4405-828d-c73b4cacb3b2"},{"cell_type":"code","source":["from langchain import hub\n","from langchain_openai import AzureChatOpenAI\n","from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n","from langchain_openai import AzureOpenAIEmbeddings\n","from langchain_openai  import AzureOpenAI\n","from langchain.schema import StrOutputParser\n","from langchain.schema.runnable import RunnablePassthrough\n","from langchain.text_splitter import MarkdownHeaderTextSplitter\n","from langchain.vectorstores.azuresearch import AzureSearch\n","from dotenv import load_dotenv\n","load_dotenv()\n","from datetime import datetime\n","import os"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":19,"statement_ids":[19],"livy_statement_state":"available","session_id":"b74fc4a9-bb55-4427-ad4e-1ea1a17872aa","state":"finished","normalized_state":"finished","queued_time":"2024-07-30T01:27:22.2022709Z","session_start_time":null,"execution_start_time":"2024-07-30T01:27:25.7930787Z","execution_finish_time":"2024-07-30T01:27:27.3061069Z","parent_msg_id":"716f7071-197d-4177-a857-283b8921dada"},"text/plain":"StatementMeta(, b74fc4a9-bb55-4427-ad4e-1ea1a17872aa, 19, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a4b66e71-2673-4cd4-affa-9006699e2013"},{"cell_type":"markdown","source":["**Configure Notebook Parameters**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"56c67952-dc91-486d-8210-81be07826fab"},{"cell_type":"code","source":["AZURE_OPENAI_ENDPOINT= \"https://test-openai-swe-central1.openai.azure.com\"\n","VECTOR_STORE_ADDRESS = \"https://cog-search-pnh3sidy433ua.search.windows.net\"\n","DOC_INTELLIGENCE_ENDPOINT = \"https://doc-intelligence-singhealth1.cognitiveservices.azure.com/\"\n","EMBEDDING_MODEL = \"text-embedding-ada-002\"\n","OPENAI_API_VERSION = \"2023-12-01-preview\"\n","INDEX_NAME = \"fabric-chunk-index\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":20,"statement_ids":[20],"livy_statement_state":"available","session_id":"b74fc4a9-bb55-4427-ad4e-1ea1a17872aa","state":"finished","normalized_state":"finished","queued_time":"2024-07-30T01:28:02.1124864Z","session_start_time":null,"execution_start_time":"2024-07-30T01:28:02.4962197Z","execution_finish_time":"2024-07-30T01:28:02.7453833Z","parent_msg_id":"bff2959c-9cf3-4931-900d-525609bf048d"},"text/plain":"StatementMeta(, b74fc4a9-bb55-4427-ad4e-1ea1a17872aa, 20, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"tags":["parameters"]},"id":"ab7db13c-34d9-46bc-89fa-6d2d4b61c3b9"},{"cell_type":"markdown","source":["**Configure AI Services Keys using Key Vault**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c7b09f25-c0ea-4888-a7b0-64a5c66f142f"},{"cell_type":"code","source":["from notebookutils.mssparkutils.credentials import getSecret\n","\n","KEYVAULT_ENDPOINT = \"https://fabric-pipeline-vault.vault.azure.net/\"\n","\n","DOC_INTELLIGENCE_KEY = getSecret(KEYVAULT_ENDPOINT, \"DOC-INTELLIGENCE-KEY\")\n","AZURE_OPENAI_API_KEY= getSecret(KEYVAULT_ENDPOINT, \"AZURE-OPENAI-API-KEY\")\n","VECTOR_STORE_PASSWORD = getSecret(KEYVAULT_ENDPOINT, \"VECTOR-STORE-PASSWORD\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":21,"statement_ids":[21],"livy_statement_state":"available","session_id":"b74fc4a9-bb55-4427-ad4e-1ea1a17872aa","state":"finished","normalized_state":"finished","queued_time":"2024-07-30T01:28:05.3214978Z","session_start_time":null,"execution_start_time":"2024-07-30T01:28:05.7077729Z","execution_finish_time":"2024-07-30T01:28:08.112925Z","parent_msg_id":"cc1abf3a-7957-49ea-afef-64a11439ac13"},"text/plain":"StatementMeta(, b74fc4a9-bb55-4427-ad4e-1ea1a17872aa, 21, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cfff30dc-58bd-4c33-9b14-5d9765175ac2"},{"cell_type":"markdown","source":["**Load the document using AI Document Intelligence prebuilt-layout mode and split it into semantic chunks using MarkdownHeaderTextSplitter**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b448b420-182e-4eb3-8e9c-31736e4a430d"},{"cell_type":"markdown","source":["**Initialize lakehouse raw and processed folder path**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"90464169-91bd-45a4-98db-e736d2ba245c"},{"cell_type":"code","source":["lakehouse_path = \"/lakehouse/default/Files/\"\n","raw_folder_path = lakehouse_path + \"raw/\" \n","processed_folder_path = lakehouse_path + \"processed/\" "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":22,"statement_ids":[22],"livy_statement_state":"available","session_id":"b74fc4a9-bb55-4427-ad4e-1ea1a17872aa","state":"finished","normalized_state":"finished","queued_time":"2024-07-30T01:28:10.2118678Z","session_start_time":null,"execution_start_time":"2024-07-30T01:28:10.5961318Z","execution_finish_time":"2024-07-30T01:28:10.8328475Z","parent_msg_id":"c8fda720-aad7-4b9a-b4ce-432fc3e65bd1"},"text/plain":"StatementMeta(, b74fc4a9-bb55-4427-ad4e-1ea1a17872aa, 22, Finished, Available, Finished)"},"metadata":{}}],"execution_count":5,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a4cca6ab-a9aa-47da-b428-0272bbb6509c"},{"cell_type":"markdown","source":["**Initalize Azure OpenAI Embedding Model**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a6123a98-5d18-41ed-9977-146dbcf4af34"},{"cell_type":"code","source":[" # Embed the splitted documents and insert into Azure Search vector store\n","aoai_embeddings = AzureOpenAIEmbeddings(\n","azure_deployment=EMBEDDING_MODEL,\n","openai_api_version=OPENAI_API_VERSION,\n","azure_endpoint=AZURE_OPENAI_ENDPOINT,\n","api_key=AZURE_OPENAI_API_KEY,\n",")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":23,"statement_ids":[23],"livy_statement_state":"available","session_id":"b74fc4a9-bb55-4427-ad4e-1ea1a17872aa","state":"finished","normalized_state":"finished","queued_time":"2024-07-30T01:28:23.5534779Z","session_start_time":null,"execution_start_time":"2024-07-30T01:28:23.9479056Z","execution_finish_time":"2024-07-30T01:28:24.1834914Z","parent_msg_id":"706e212d-712d-4918-9d9b-3ae7d30290d9"},"text/plain":"StatementMeta(, b74fc4a9-bb55-4427-ad4e-1ea1a17872aa, 23, Finished, Available, Finished)"},"metadata":{}}],"execution_count":6,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fe9e6870-2e16-4833-bd5f-7be7d590013e"},{"cell_type":"markdown","source":["**Chunk documents and Output the Semantic Chunks (splits) into results folder**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"79ed8909-05a9-4ee7-97a2-1851e1954362"},{"cell_type":"code","source":["def chunk_documents(file_name):\n","    # Initiate Azure AI Document Intelligence to load the document. You can either specify file_path or url_path to load the document.\n","    loader = AzureAIDocumentIntelligenceLoader(file_path=raw_folder_path + file_name, api_key=DOC_INTELLIGENCE_KEY, api_endpoint=DOC_INTELLIGENCE_ENDPOINT, api_model=\"prebuilt-layout\")\n","    docs = loader.load()\n","\n","\n","    # Split the document into chunks base on markdown headers.\n","    headers_to_split_on = [\n","        #(\"#\", \"Header 1\"),\n","        (\"##\", \"Header 2\"),\n","        # (\"###\", \"Header 3\"),\n","    ]\n","    text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n","\n","    docs_string = docs[0].page_content\n","    splits = text_splitter.split_text(docs_string)\n","    print(\"Length of splits: \" + str(len(splits)))\n","\n","    run_prefix = datetime.now().strftime(\"%Y%m%d%H%M%S\")   \n","    output_folder = processed_folder_path + f\"chunks_{file_name}_{run_prefix}\"  # Specify the folder path where you want to save the files\n","\n","    os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n","\n","    for split in splits:\n","        # Specify the folder path where you want to save the files\n","        for i, split in enumerate(splits):\n","            file_path = os.path.join(output_folder, f\"split_{i}.MD\")  # Specify the file path for each split\n","            with open(file_path, \"w\") as file:\n","                file.write(split.page_content)\n","    print(\"Chunks generated in folder : \"+ output_folder)\n","    return splits"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":25,"statement_ids":[25],"livy_statement_state":"available","session_id":"b74fc4a9-bb55-4427-ad4e-1ea1a17872aa","state":"finished","normalized_state":"finished","queued_time":"2024-07-30T01:29:39.2467655Z","session_start_time":null,"execution_start_time":"2024-07-30T01:29:39.6324187Z","execution_finish_time":"2024-07-30T01:29:39.9926336Z","parent_msg_id":"fae36cbf-a9a4-459b-9215-ee81e54a8d4b"},"text/plain":"StatementMeta(, b74fc4a9-bb55-4427-ad4e-1ea1a17872aa, 25, Finished, Available, Finished)"},"metadata":{}}],"execution_count":8,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"eb7b75c6-0e2b-4197-bf06-67ea8d3a9550"},{"cell_type":"markdown","source":["**Embed and index the chunks**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5646cf1f-4db4-4b20-b1b8-05329d6e5c96"},{"cell_type":"code","source":["def embedd_index_documents(splits):\n","    vector_store: AzureSearch = AzureSearch(\n","        azure_search_endpoint=VECTOR_STORE_ADDRESS,\n","        azure_search_key=VECTOR_STORE_PASSWORD,\n","        index_name=INDEX_NAME,\n","        embedding_function=aoai_embeddings.embed_query,\n","    )\n","\n","    vector_store.add_documents(documents=splits)   \n","    print (\"Embeding of chunks and Indexing to AI Search is completed\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":27,"statement_ids":[27],"livy_statement_state":"available","session_id":"b74fc4a9-bb55-4427-ad4e-1ea1a17872aa","state":"finished","normalized_state":"finished","queued_time":"2024-07-30T01:30:03.4105343Z","session_start_time":null,"execution_start_time":"2024-07-30T01:30:04.1475937Z","execution_finish_time":"2024-07-30T01:30:04.3893832Z","parent_msg_id":"7f75b0ee-f229-4bc7-9db4-0d67f17e1752"},"text/plain":"StatementMeta(, b74fc4a9-bb55-4427-ad4e-1ea1a17872aa, 27, Finished, Available, Finished)"},"metadata":{}}],"execution_count":10,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ee7b539a-c14c-4f7f-ad55-c51e7708f62d"},{"cell_type":"markdown","source":["**Move the raw file to processed folder**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d4318096-9141-401d-864f-65f5b014a74e"},{"cell_type":"code","source":["def mov_raw_processed(file_name):\n","    os.rename(raw_folder_path + file_name, processed_folder_path + file_name)\n","    print(\"Moved file from raw folder to processed folder\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":28,"statement_ids":[28],"livy_statement_state":"available","session_id":"b74fc4a9-bb55-4427-ad4e-1ea1a17872aa","state":"finished","normalized_state":"finished","queued_time":"2024-07-30T01:30:29.4589121Z","session_start_time":null,"execution_start_time":"2024-07-30T01:30:30.0766578Z","execution_finish_time":"2024-07-30T01:30:30.3315892Z","parent_msg_id":"3b53e1d9-d120-47ac-b603-a939834f6b27"},"text/plain":"StatementMeta(, b74fc4a9-bb55-4427-ad4e-1ea1a17872aa, 28, Finished, Available, Finished)"},"metadata":{}}],"execution_count":11,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f0993032-73e9-4701-9a13-67487ff04b1d"},{"cell_type":"markdown","source":["**Main Method: Invoke File Processing in Raw Folder**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2b84905c-22d4-4a6f-a907-6097a0581306"},{"cell_type":"code","source":["def process_files(file_name):\n","    print(\"Processing File Started : \"+file_name)\n","    splits = chunk_documents(file_name)\n","    embedd_index_documents(splits)\n","    mov_raw_processed(file_name)\n","    print(\"Processing File Completed : \"+file_name)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":29,"statement_ids":[29],"livy_statement_state":"available","session_id":"b74fc4a9-bb55-4427-ad4e-1ea1a17872aa","state":"finished","normalized_state":"finished","queued_time":"2024-07-30T01:31:30.2312669Z","session_start_time":null,"execution_start_time":"2024-07-30T01:31:30.6788301Z","execution_finish_time":"2024-07-30T01:31:30.9438834Z","parent_msg_id":"87e4696c-7211-42ce-800e-d90931c19071"},"text/plain":"StatementMeta(, b74fc4a9-bb55-4427-ad4e-1ea1a17872aa, 29, Finished, Available, Finished)"},"metadata":{}}],"execution_count":12,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ec5e8cc7-9979-4aeb-99ba-a7f6107c63d5"},{"cell_type":"code","source":["files = os.listdir(raw_folder_path)\n","\n","for file_name in files:\n","    process_files(file_name)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":31,"statement_ids":[31],"livy_statement_state":"available","session_id":"b74fc4a9-bb55-4427-ad4e-1ea1a17872aa","state":"finished","normalized_state":"finished","queued_time":"2024-07-30T01:35:02.1965172Z","session_start_time":null,"execution_start_time":"2024-07-30T01:35:02.691932Z","execution_finish_time":"2024-07-30T01:35:23.74513Z","parent_msg_id":"17d78f2d-c0a7-4670-b3cc-18b9afa7a0ab"},"text/plain":"StatementMeta(, b74fc4a9-bb55-4427-ad4e-1ea1a17872aa, 31, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing File Started : 2310.07488.pdf\nLength of splits: 8\nChunks generated in folder : /lakehouse/default/Files/processed/chunks_2310.07488.pdf_20240730013514\nEmbeding of chunks and Indexing to AI Search is completed\nMoved file from raw folder to processed folder\nProcessing File Completed : 2310.07488.pdf\n"]}],"execution_count":14,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6376a17a-d754-49f1-903c-98795050dc0b"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"771fc3b7-5ab9-4224-a72c-d75b73931910","default_lakehouse_name":"SingHealth_OneLake","default_lakehouse_workspace_id":"ac456f76-ca57-4ea0-bca2-bdd98c5e60fc"}}},"nbformat":4,"nbformat_minor":5}